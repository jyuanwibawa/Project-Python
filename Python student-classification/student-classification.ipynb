{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4362,"status":"ok","timestamp":1722924928757,"user":{"displayName":"169_JP. Rafi Radiktya Arkan","userId":"14075227126774705294"},"user_tz":-420},"id":"e452Nh2vnG0r","outputId":"352dfcbe-8c6b-48a3-b2b8-afdc1d1fbeff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting MTCNN\n","  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from MTCNN) (3.4.1)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from MTCNN) (4.10.0.84)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (0.12.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (0.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->MTCNN) (24.1)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=2.0.0->MTCNN) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.0.0->MTCNN) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.0.0->MTCNN) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->MTCNN) (0.1.2)\n","Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: MTCNN\n","Successfully installed MTCNN-0.1.1\n"]}],"source":["pip install MTCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNCz5jYsQauA"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix, classification_report\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.optimizers import Adam\n","from mtcnn import MTCNN\n","from google.colab import drive\n","from tensorflow.keras.applications import InceptionResNetV2\n","from keras.applications import ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34223,"status":"ok","timestamp":1722842900040,"user":{"displayName":"01 Achmad Royhan Kamil","userId":"13521125306205175920"},"user_tz":-420},"id":"8p879tNbqqqH","outputId":"a68ab5c0-bd60-488a-9b89-f396ba366204"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbHi_PQcrHGs"},"outputs":[],"source":["extracted_path = '/content/drive/MyDrive/student-classification/Extracted_Dataset1'\n","\n","dataset_path = '/content/drive/MyDrive/student-classification/Combined_Dataset'\n","\n","if not os.path.exists(extracted_path):\n","    os.makedirs(extracted_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6QsBSigrKd7"},"outputs":[],"source":["# for category in os.listdir(dataset_path):\n","#     category_path = os.path.join(dataset_path, category)\n","#     if os.path.isdir(category_path):\n","#         for image_file in os.listdir(category_path):\n","#             image_path = os.path.join(category_path, image_file)\n","#             image = Image.open(image_path)\n","#             pixels = np.array(image)\n","#             detector = MTCNN()\n","#             results = detector.detect_faces(pixels)\n","#             if len(results) == 0:\n","#                 face_array = None\n","#             else:\n","#               x1, y1, width, height = results[0]['box']\n","#               x1, y1 = abs(x1), abs(y1)\n","#               x2, y2 = x1 + width, y1 + height\n","\n","#               face = pixels[y1:y2, x1:x2]\n","#               image = Image.fromarray(face)\n","#               image = image.resize((160, 160))\n","#               face_array = img_to_array(image)\n","#             if face_array is not None:\n","#                 save_path = os.path.join(extracted_path, category)\n","#                 if not os.path.exists(save_path):\n","#                     os.makedirs(save_path)\n","#                 face_image = Image.fromarray(np.uint8(face_array))\n","#                 face_image.save(os.path.join(save_path, image_file))\n","\n","# print(\"Selesai Melakukan extraksi wajah\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269796,"status":"ok","timestamp":1722843601889,"user":{"displayName":"01 Achmad Royhan Kamil","userId":"13521125306205175920"},"user_tz":-420},"id":"g63vxoNXkTtl","outputId":"f50fbee8-fdb5-4374-d046-1186f1ceae9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Selesai Melakukan Augmentasi\n"]}],"source":["\n","augment_datagen = ImageDataGenerator(\n","    rescale=1.0/255,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    rotation_range=40,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,\n","    zoom_range=0.3,\n","    brightness_range=[0.8, 1.2],\n","    channel_shift_range=30.0,\n","    fill_mode='nearest'\n",")\n","\n","def augment_images(input_folder, num_augmented_images):\n","    image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n","    num_original_images = len(image_files)\n","    num_augmentations_per_image = (num_augmented_images - num_original_images) // num_original_images\n","\n","    for image_file in image_files:\n","        img_path = os.path.join(input_folder, image_file)\n","        img = load_img(img_path)\n","        x = img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","\n","\n","        aug_iter = augment_datagen.flow(x, batch_size=1)\n","\n","\n","        for i in range(num_augmentations_per_image):\n","            batch = next(aug_iter)\n","            augmented_img = batch[0]\n","            augmented_img = np.uint8(augmented_img * 255)\n","            augmented_img_path = os.path.join(input_folder, f\"aug_{i}.jpg\")\n","            augmented_img_pil = Image.fromarray(augmented_img)\n","            augmented_img_pil.save(augmented_img_path)\n","\n","\n","    remaining_augments = num_augmented_images - num_original_images * (num_augmentations_per_image + 1)\n","    for i in range(remaining_augments):\n","        img_file = image_files[i % num_original_images]\n","        img_path = os.path.join(input_folder, img_file)\n","        img = load_img(img_path)\n","        x = img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","\n","        aug_iter = augment_datagen.flow(x, batch_size=1)\n","        batch = next(aug_iter)\n","        augmented_img = batch[0]\n","        augmented_img = np.uint8(augmented_img * 255)\n","        augmented_img_path = os.path.join(input_folder, f\"aug_{os.path.splitext(img_file)[0]}_extra_{i}.jpg\")\n","        augmented_img_pil = Image.fromarray(augmented_img)\n","        augmented_img_pil.save(augmented_img_path)\n","\n","for folder in os.listdir(extracted_path):\n","    input_folder = os.path.join(extracted_path, folder)\n","    augment_images(input_folder, num_augmented_images=300)\n","\n","print(\"Selesai Melakukan Augmentasi\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1472,"status":"ok","timestamp":1722843603360,"user":{"displayName":"01 Achmad Royhan Kamil","userId":"13521125306205175920"},"user_tz":-420},"id":"mUdeDIUDm8Ns","outputId":"1ac85155-4ebb-4d41-dd49-86494821fa09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 18028 images belonging to 33 classes.\n","Found 4491 images belonging to 33 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.2,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","image_height, image_width = 160, 160\n","batch_size = 32\n","\n","train_generator = train_datagen.flow_from_directory(extracted_path, subset='training', batch_size=batch_size, target_size=(image_height, image_width), class_mode=\"categorical\")\n","validation_generator = train_datagen.flow_from_directory(extracted_path, subset='validation', batch_size=batch_size, target_size=(image_height, image_width), class_mode=\"categorical\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10632,"status":"ok","timestamp":1722843614406,"user":{"displayName":"01 Achmad Royhan Kamil","userId":"13521125306205175920"},"user_tz":-420},"id":"aF8BpZqZ8aKe","outputId":"f9496cce-9ed7-4dfe-d024-e2856be37624"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"]}],"source":["base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(image_height, image_width, 3))\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(512, activation='relu')(x)\n","predictions = Dense(len(os.listdir(extracted_path)), activation='softmax')(x)\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"xb9PYTGDECro","outputId":"2e1b6e19-5e80-4349-93f1-03b76d6c3c20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2764s\u001b[0m 5s/step - accuracy: 0.2642 - loss: 2.7561 - val_accuracy: 0.7094 - val_loss: 1.0250\n","Epoch 2/10\n","\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2684s\u001b[0m 5s/step - accuracy: 0.5208 - loss: 1.6216 - val_accuracy: 0.8301 - val_loss: 0.6499\n","Epoch 3/10\n","\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2659s\u001b[0m 5s/step - accuracy: 0.5891 - loss: 1.3870 - val_accuracy: 0.8297 - val_loss: 0.5998\n","Epoch 4/10\n","\u001b[1m234/564\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21:00\u001b[0m 4s/step - accuracy: 0.6314 - loss: 1.2386"]}],"source":["model.fit(train_generator, validation_data=validation_generator, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CHXPku5gJ6uh"},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.preprocessing import LabelEncoder\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVwVO7UCD9uX"},"outputs":[],"source":["\n","for layer in base_model.layers[:100]:\n","    layer.trainable = False\n","for layer in base_model.layers[100:]:\n","    layer.trainable = True\n","\n","model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WizDktbNELFX"},"outputs":[],"source":["model.fit(train_generator, validation_data=validation_generator, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2651pVWEL6m"},"outputs":[],"source":["def extract_embeddings(model, generator):\n","    embeddings = []\n","    labels = []\n","    for i in range(len(generator)):\n","        x, y = generator[i]\n","        embedding = model.predict(x)\n","        embeddings.append(embedding)\n","        labels.append(y)\n","    embeddings = np.vstack(embeddings)\n","    labels = np.vstack(labels)\n","    return embeddings, labels\n","\n","train_embeddings, train_labels = extract_embeddings(base_model, train_generator)\n","label_encoder = LabelEncoder()\n","train_labels_encoded = label_encoder.fit_transform(train_labels.argmax(axis=1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yi7GmVRKEbzp"},"outputs":[],"source":["with open('embeddings.pkl', 'wb') as f:\n","    pickle.dump((train_embeddings, train_labels_encoded), f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2l58DDjA2gt"},"outputs":[],"source":["Y_pred_train = model.predict(train_generator)\n","y_pred_train = np.argmax(Y_pred_train, axis=1)\n","y_true_train = train_generator.classes\n","Y_pred_val = model.predict(validation_generator)\n","y_pred_val = np.argmax(Y_pred_val, axis=1)\n","y_true_val = validation_generator.classes\n","\n","class_labels = list(validation_generator.class_indices.keys())\n","\n","cm_train = confusion_matrix(y_true_train, y_pred_train)\n","print(\"Confusion Matrix - Training Data\")\n","print(cm_train)\n","\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_train, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix - Training Data')\n","plt.show()\n","\n","cm_val = confusion_matrix(y_true_val, y_pred_val)\n","print(\"Confusion Matrix - Validation Data\")\n","print(cm_val)\n","\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_val, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix - Validation Data')\n","plt.show()\n","\n","print(\"Classification Report - Training Data\")\n","report_train = classification_report(y_true_train, y_pred_train, target_names=class_labels)\n","print(report_train)\n","\n","print(\"Classification Report - Validation Data\")\n","report_val = classification_report(y_true_val, y_pred_val, target_names=class_labels)\n","print(report_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSYAOXDyxrV5"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}